---
title: "Analyzing Data From Documents"
subtitle: "Findings"
---
Army Doctrine Publication serves as the baseline document. 
The below analysis is conducted to determine the similarity between the good performer and bad performer GAT items. Most of the documents have a cosine similarity greater than 0.9 indicating high similarity. Since most of the words are common in the good performer and bad performer documents high similarity is obeserved.
<div>
<div class="column">
<p align="center" style= "margin-top: 50px;">
![Similarity Analysis using BERT](img/part2-bert.png){width=90%}
*Similarity Analysis using BERT*
</p>
</div>


<div class="column">
<p align="center" style= "margin-top: 50px;">
![Similarity Analysis using GPT](img/part2-gpt.png){width=90%} 
*Similarity Analysis using GPT*
</p>
</div>
</div>

The below analysis is conducted to determine the similarity between the GAT items and ADP. Most of the documents have a cosine similarity greater than 0.8 indicating high conceptual similarity between GAT items and ADP. The ADP not only specifies the characteristics of a good performer it also specifies the characteristics a good performer should not exhibit.Therefore even the bad performer documents have high conceptual similarity to the ADP. 
<div align= "center">

<p align="center" style= "margin-top: 50px;">
![Similarity of GAT item*](img/part2-cosine.png){width=80%}
Similarity of GAT doc to ADP
</p>
</div>
<br>
<br>

The below analysis is conducted to explore the prescriptive and descriptive behaviors associated with Soldier and unit performance.
<br>
<br>
</div>

## *Verb Extraction and Analysis*

```{r echo = FALSE}
library(DT)
library(tidyr)
library(dplyr)

read.csv("../../data/verbs.csv") %>% 
  rename("Verb" = lemma, "Count" = count) %>%
  datatable(caption = 'Table 1: This is a simple caption for the table.',
    options = list(pageLength = 10, dom = 'tip'), rownames = FALSE)

read.csv("../../data/top_verb_phrases.csv") %>% select(-X) %>%
  rename("Verb" = lemma, "Count" = verb_count,
          "Cooccurring Word" = item2, 
         "Coccurence Count" = cooccurence_count) %>%
  datatable(caption = 'Table 1: This is a simple caption for the table.',
    options = list(pageLength = 10, dom = 'tip'), rownames = FALSE)

read.csv("../../data/verbs_gat.csv") %>% arrange(-verb_sum) %>% 
  mutate(document = stringr::str_remove(document, "GAT"),
         document = stringr::str_remove(document, ".txt"),
         document = stringr::str_replace_all(document, "_", " ")) %>%
  rename("Global Assessment Tool (GAT) Item" = document, "Verb Alignment (Count)" = verb_count, "Verb Alignment (Weighted Count)" = verb_sum) %>%
  datatable(caption = 'Table 1: This is a simple caption for the table.',
    options = list(pageLength = 10, dom = 'tip'), rownames = FALSE)
```

