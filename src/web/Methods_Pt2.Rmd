---
title: "Analyzing Data From Documents"
subtitle: "Methods"
---


### Data Representation

<strong> Word Embeddings: </strong> To determine the similarity between the documents word embeddings was used.The word embedding techniques are used to represent words mathematically. Word Embeddings are a method of extracting features out of text so that we can input those features into a machine learning model to work with text data. They try to preserve syntactical and semantic information. It is an approach for representing words and documents. Word Embedding or Word Vector is a numeric vector input that represents a word in a lower-dimensional space. It allows words with similar meaning to have a similar representation. 

### Models
Hugging face is an open source AI platform where we can create, build, and train models for open source collaboration. Hugging Face's Transformer library lets you connect to these models, send tasks, and receive outputs without having to set them up yourself. You can also download models, train them with your own data, or quickly create a Space. This makes it easy to find models to complete any kind of task, connect them with your own code, and start getting results. We have used the below two hugging face models. 

1. <strong>BERT:</strong> Bidirectional Encoder Representations from Transformers is one of the extensively used hugging face model. Since this language model is bidirectionally trained, it can have a deeper sense of language context and flow than single-direction. BERT is designed to help computers understand the meaning of ambiguous language in text by using surrounding text to establish context. language models. 

2. <strong>GPT2:</strong> It is a transformer based language model designed to understand and generate human-like text by predicting the likelihood of words or sentences given the context provided to it. GPT-2 can perform various language-related tasks, such as generating coherent text, answering questions, completing sentences, and more. Its ability to generate contextually relevant responses has made it a powerful tool for natural language processing applications.


3. <strong>Clustering:</strong> K-means clustering is important in document analysis because it allows us to group similar documents together based on their content. It can be used to automatically categorize large sets of documents into distinct groups, making it easier to manage and retrieve relevant information.

### Metric
<strong>Cosine Similarity: </strong> It is used to measure the similarity between two documents based on their content. It calculates the cosine of the angle between two document vectors in a high-dimensional space, where each dimension represents a term (word) in the documents.