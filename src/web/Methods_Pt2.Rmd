---
title: "Project Title"
subtitle: "Methods"
---

## *Word Embeddings*
To determine the similarity between the documents word embeddings was used.The word embedding techniques are used to represent words mathematically. Word Embeddings are a method of extracting features out of text so that we can input those features into a machine learning model to work with text data. They try to preserve syntactical and semantic information. It is an approach for representing words and documents. Word Embedding or Word Vector is a numeric vector input that represents a word in a lower-dimensional space. It allows words with similar meaning to have a similar representation. 

