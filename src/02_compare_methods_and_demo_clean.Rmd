---
title: "Demo cleaning"
author: "Joanna Schroeder"
date: "6/20/2023"
output: html_document
---

```{r setup, include=FALSE}
library(tidyr)
library(dplyr)
library(stringr)

armor_gpt <- readr::read_csv("../data/12_06_2023ArmorGPT.csv") %>% mutate(source = "gpt") %>% 
  mutate(Type = ifelse(`Type of Assignment` == "Key Developmental", "KD", "DEV"), MOS = "Armor") %>% select(-`Type of Assignment`)
armor_r <- readr::read_csv("../data/14_06_2023_ArmorR.csv") %>% mutate(source = "regex") %>% select(-`...1`)
ada_gpt <- readr::read_csv("../data/12_06_2023AirDefenseArtilleryGPT.csv") %>% mutate(source = "gpt") %>% 
  mutate(Type = ifelse(`Type of Assignment` == "Key Developmental", "KD", "DEV"), MOS = "ADA") %>% select(-`Type of Assignment`)
ada_r <- readr::read_csv("../data/15_06_2023_ADAR.csv") %>% mutate(source = "regex",MOS = "ADA") %>% select(-`...1`)

data <- rbind(armor_gpt, armor_r) %>% rbind(ada_gpt) %>% rbind(ada_r)

table(data$Rank, data$source)
table(data$MOS, data$source)
```

# Agreement without cleaning
```{r}
gpt <- data %>% filter(source == "gpt") %>% pull(Assignment)
regex <- data %>% filter(source == "regex") %>% pull(Assignment)

c(gpt, regex) %>% length()
c(gpt, regex) %>% unique() %>% length()

setdiff(gpt, regex) %>% length()
setdiff(regex, gpt) %>% length()
intersect(regex, gpt) %>% length()
```

# Agreement with basic cleaning
```{r}
# casing 
data <- data %>% mutate(Assignment = tolower(Assignment))

gpt <- data %>% filter(source == "gpt") %>% pull(Assignment)
regex <- data %>% filter(source == "regex") %>% pull(Assignment)

c(gpt, regex) %>% unique() %>% length()

setdiff(gpt, regex) %>% length()
setdiff(regex, gpt) %>% length()
intersect(regex, gpt) %>% length()
```

# Agreement with fuzzy matching
```{r}
library(stringdist)

matrix <- stringsimmatrix(data$Assignment, data$Assignment)
matrix[lower.tri(matrix, diag = FALSE)] <- 0
matches <- as.data.frame(which(matrix >= 0.70 & matrix != 1, arr.ind = TRUE)) %>% filter(row != col)

data <- data %>% tibble::rownames_to_column() %>% mutate(rowname = as.integer(rowname)) %>% left_join(matches, by = c("rowname" = "row"))
data <- data %>% mutate(match = ifelse(!is.na(col), col, rowname)) %>% 
  mutate(Assignment = Assignment[match]) %>% select(-col, -rowname, -match)

gpt <- data %>% filter(source == "gpt") %>% pull(Assignment)
regex <- data %>% filter(source == "regex") %>% pull(Assignment)

c(gpt, regex) %>% unique() %>% length()

setdiff(gpt, regex) %>% length()
setdiff(regex, gpt) %>% length()
intersect(regex, gpt) %>% length()
```

## Summary of findings

For the ADA and Armor branches, regex either performs about the same or better than chat-gpt (i.e. finds more assignment names). Within these branches, we find 225 assignments using both methods. Without any cleaning, 180 of those assignments are unique. Regex finds more unique assignments than chat-gpt. With basic cleaning (lowercasing only), we have 167 unique assignments. Using fuzzymatching, depending on our threshold, we can achieve even less unique assignments. 

Questions: What other basic cleaning should we do? How will we know where to set our fuzzymatching threshold?

